{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9HZHDjK9CAYl",
    "outputId": "88b1b9d6-6cf9-40ac-a2c7-eae1bedcc726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'GNN-Resource-Management'...\n",
      "remote: Enumerating objects: 209, done.\u001b[K\n",
      "remote: Counting objects: 100% (209/209), done.\u001b[K\n",
      "remote: Compressing objects: 100% (141/141), done.\u001b[K\n",
      "remote: Total 209 (delta 110), reused 158 (delta 62), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (209/209), 236.41 KiB | 1.27 MiB/s, done.\n",
      "Resolving deltas: 100% (110/110), done.\n",
      "/content/GNN-Resource-Management/NewDir\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/LeGiangK62/GNN-Resource-Management.git\n",
    "%cd GNN-Resource-Management/NewDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "euhBKmR3CSf0"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import torch\n",
    "!pip install torch_geometric\n",
    "\n",
    "# Optional dependencies:\n",
    "if torch.cuda.is_available():\n",
    "  !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
    "else:\n",
    "  !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PSrar76fCI8E"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU, Sigmoid\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import Linear, HGTConv\n",
    "\n",
    "from WSN_GNN import generate_channels_wsn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cSBfHOVCgbE"
   },
   "source": [
    "# Create HeteroData from the wireless system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Lqs7nC0tCOYM"
   },
   "outputs": [],
   "source": [
    "#region Create HeteroData from the wireless system\n",
    "def convert_to_hetero_data(channel_matrices):\n",
    "    graph_list = []\n",
    "    num_sam, num_aps, num_users = channel_matrices.shape\n",
    "    for i in range(num_sam):\n",
    "        x1 = torch.ones(num_users, 1)\n",
    "        x2 = torch.ones(num_users, 1)  # power allocation\n",
    "        x3 = torch.ones(num_users, 1)  # ap selection?\n",
    "        user_feat = torch.cat((x1,x2,x3),1)  # features of user_node\n",
    "        ap_feat = torch.zeros(num_aps, num_aps_features)  # features of user_node\n",
    "        edge_feat_uplink = channel_matrices[i, :, :].reshape(-1, 1)\n",
    "        edge_feat_downlink = channel_matrices[i, :, :].reshape(-1, 1)\n",
    "        graph = HeteroData({\n",
    "            'user': {'x': user_feat},\n",
    "            'ap': {'x': ap_feat}\n",
    "        })\n",
    "        # Create edge types and building the graph connectivity:\n",
    "        graph['user', 'uplink', 'ap'].edge_attr = torch.tensor(edge_feat_uplink, dtype=torch.float)\n",
    "        graph['ap', 'downlink', 'user'].edge_attr = torch.tensor(edge_feat_downlink, dtype=torch.float)\n",
    "        graph['user', 'uplink', 'ap'].edge_index = torch.tensor(adj_matrix(num_users, num_aps).transpose(), dtype=torch.int64)\n",
    "        graph['ap', 'downlink', 'user'].edge_index = torch.tensor(adj_matrix(num_aps, num_users).transpose(),\n",
    "                                                                dtype=torch.int64)\n",
    "\n",
    "        # graph['ap', 'downlink', 'user'].edge_attr  = torch.tensor(edge_feat_downlink, dtype=torch.float)\n",
    "        graph_list.append(graph)\n",
    "    return graph_list\n",
    "\n",
    "\n",
    "def adj_matrix(num_from, num_dest):\n",
    "    adj = []\n",
    "    for i in range(num_from):\n",
    "        for j in range(num_dest):\n",
    "            adj.append([i, j])\n",
    "    return np.array(adj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMJBmS42Ckc-"
   },
   "source": [
    "# Build Heterogeneous GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "3Oigpa4mCVBk"
   },
   "outputs": [],
   "source": [
    "#region Build Heterogeneous GNN\n",
    "class HetNetGNN(torch.nn.Module):\n",
    "    def __init__(self, data, hidden_channels, out_channels, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_dict = torch.nn.ModuleDict()\n",
    "        for node_type in data.node_types:\n",
    "            self.lin_dict[node_type] = Linear(-1, hidden_channels)\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HGTConv(hidden_channels, hidden_channels, data.metadata(),\n",
    "                           num_heads, group='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "        \n",
    "        self.lin1 = Linear(hidden_channels, out_channels)\n",
    "        self.round = RoundActivation()\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = {\n",
    "            node_type: self.lin_dict[node_type](x).relu_()\n",
    "            for node_type, x in x_dict.items()\n",
    "        }\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            \n",
    "        original = x_dict['user']\n",
    "        power = self.lin(x_dict['user'])\n",
    "        ap_selection = self.round(power)\n",
    "        out = torch.concat((original[:,0], power[:,1], ap_selection[:,1]), 1)\n",
    "        \n",
    "        \n",
    "        return self.lin(x_dict['user'])\n",
    "\n",
    "class EdgeConv(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def foward(self, graph, inputs):\n",
    "        return 1\n",
    "    \n",
    "    \n",
    "class RoundActivation(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.round(x)\n",
    "\n",
    "#endregion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xARv-2yLCnwN"
   },
   "source": [
    "# Training and Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3zupX9hyCXoc"
   },
   "outputs": [],
   "source": [
    "#region Training and Testing functions\n",
    "def loss_function(output, batch, is_train=True):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    num_user = batch['user']['x'].shape[0]\n",
    "    num_ap = batch['ap']['x'].shape[0]\n",
    "    ##\n",
    "    channel_matrix = batch['user', 'ap']['edge_attr']\n",
    "    power_max = batch['user']['x'][:, 0]\n",
    "    power = batch['user']['x'][:, 1]\n",
    "    ap_selection = batch['user']['x'][:, 2]\n",
    "    index = torch.arange(num_user)\n",
    "\n",
    "    G = torch.reshape(channel_matrix, (-1, num_ap, num_user))\n",
    "    # P = torch.reshape(power, (-1, num_ap, num_user)) #* p_max\n",
    "    P = torch.zeros(G.shape)\n",
    "    P[0, ap_selection[index], index] = power_max * power\n",
    "    ##\n",
    "    desired_signal = torch.sum(torch.mul(P, G), dim=2).unsqueeze(-1)\n",
    "    P_UE = torch.sum(P, dim=1).unsqueeze(-1)\n",
    "    all_received_signal = torch.matmul(G, P_UE)\n",
    "    # new_noise = torch.from_numpy(noise_matrix).to(device)\n",
    "    interference = all_received_signal - desired_signal #+ new_noise\n",
    "    rate = torch.log(1 + torch.div(desired_signal, interference))\n",
    "    sum_rate = torch.mean(torch.sum(rate, 1))\n",
    "    mean_power = torch.mean(torch.sum(P_UE, 1))\n",
    "\n",
    "    if is_train:\n",
    "        return torch.neg(sum_rate / mean_power)\n",
    "    else:\n",
    "        return sum_rate / mean_power\n",
    "\n",
    "\n",
    "\n",
    "def train(data_loader):\n",
    "    model.train()\n",
    "    device_type = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    total_examples = total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device_type)\n",
    "        # batch_size = batch['user'].batch_size\n",
    "        out = model(batch.x_dict, batch.edge_index_dict)\n",
    "        tmp_loss = loss_function(out, data, True)\n",
    "        tmp_loss.backward()\n",
    "        optimizer.step()\n",
    "        #total_examples += batch_size\n",
    "        total_loss += float(tmp_loss) #* batch_size\n",
    "\n",
    "    return total_loss #/ total_examples\n",
    "\n",
    "\n",
    "def test(data_loader):\n",
    "    model.eval()\n",
    "    device_type = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    total_examples = total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        batch = batch.to(device_type)\n",
    "        # batch_size = batch['user'].batch_size\n",
    "        out = model(batch.x_dict, batch.edge_index_dict)\n",
    "        tmp_loss = loss_function(out, batch, False)\n",
    "        #total_examples += batch_size\n",
    "        total_loss += float(tmp_loss) #* batch_size\n",
    "\n",
    "    return total_loss #/ total_examples\n",
    "#endregion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYnfbYmsCa59"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7acs4Y0uCdoD"
   },
   "outputs": [],
   "source": [
    "K = 3  # number of APs\n",
    "N = 5  # number of nodes\n",
    "R = 10  # radius\n",
    "\n",
    "num_users_features = 3\n",
    "num_aps_features = 3\n",
    "\n",
    "num_train = 2  # number of training samples\n",
    "num_test = 4  # number of test samples\n",
    "\n",
    "reg = 1e-2\n",
    "pmax = 1\n",
    "var_db = 10\n",
    "var = 1 / 10 ** (var_db / 10)\n",
    "var_noise = 10e-11\n",
    "\n",
    "power_threshold = 2.0\n",
    "\n",
    "X_train, noise_train, pos_train, adj_train, index_train = generate_channels_wsn(K, N, num_train, var_noise, R)\n",
    "X_test, noise_test, pos_test, adj_test, index_test = generate_channels_wsn(K + 1, N + 10, num_test, var_noise, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "hCH-zKEADSQ8"
   },
   "outputs": [],
   "source": [
    "# Maybe need normalization here\n",
    "train_data = convert_to_hetero_data(X_train)\n",
    "test_data = convert_to_hetero_data(X_test)\n",
    "\n",
    "batchSize = 100\n",
    "\n",
    "train_loader = DataLoader(train_data, batchSize, shuffle=True, num_workers=1)\n",
    "test_loader = DataLoader(test_data, batchSize, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "0_RqWpsQDVmV"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# # print(data.edge_index_dict)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 11\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GNN-Resource\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[39], line 32\u001b[0m, in \u001b[0;36mHetNetGNN.forward\u001b[1;34m(self, x_dict, edge_index_dict)\u001b[0m\n\u001b[0;32m     30\u001b[0m power \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     31\u001b[0m ap_selection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mround(x_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 32\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43map_selection\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data = train_data[0]\n",
    "data = data.to(device)\n",
    "\n",
    "model = HetNetGNN(data, hidden_channels=64, out_channels=4, num_heads=2, num_layers=1)\n",
    "model = model.to(device)\n",
    "\n",
    "# # print(data.edge_index_dict)\n",
    "with torch.no_grad():\n",
    "    output = model(data.x_dict, data.edge_index_dict)\n",
    "print(output)\n",
    "print(data)\n",
    "\n",
    "# data = test_data[0]\n",
    "# data = data.to(device)\n",
    "#\n",
    "# with torch.no_grad():\n",
    "#     output = model(data.x_dict, data.edge_index_dict)\n",
    "#     print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJYiXcE9Cs2M"
   },
   "source": [
    "## Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "_AdzgAL4CqOM",
    "outputId": "e588b0d7-1a7e-4916-c594-ed5fd14d4add"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tensors used as indices must be long, int, byte or bool tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m101\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m test(test_loader)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 43\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(data_loader)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# batch_size = batch['user'].batch_size\u001b[39;00m\n\u001b[0;32m     42\u001b[0m out \u001b[38;5;241m=\u001b[39m model(batch\u001b[38;5;241m.\u001b[39mx_dict, batch\u001b[38;5;241m.\u001b[39medge_index_dict)\n\u001b[1;32m---> 43\u001b[0m tmp_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m tmp_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     45\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[9], line 16\u001b[0m, in \u001b[0;36mloss_function\u001b[1;34m(output, batch, is_train)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# P = torch.reshape(power, (-1, num_ap, num_user)) #* p_max\u001b[39;00m\n\u001b[0;32m     15\u001b[0m P \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(G\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 16\u001b[0m P[\u001b[38;5;241m0\u001b[39m, ap_selection[index], index] \u001b[38;5;241m=\u001b[39m power_max \u001b[38;5;241m*\u001b[39m power\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m##\u001b[39;00m\n\u001b[0;32m     18\u001b[0m desired_signal \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mmul(P, G), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: tensors used as indices must be long, int, byte or bool tensors"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.9)\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {loss:.4f}, Test Reward: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTIh-q4IDXsU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
